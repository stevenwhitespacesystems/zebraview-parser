package com.whitespacesystems.parser.benchmark

import com.whitespacesystems.parser.BaselineComparison
import com.whitespacesystems.parser.BenchmarkResult
import com.whitespacesystems.parser.PerformanceBaseline
import com.whitespacesystems.parser.PerformanceThresholds
import com.whitespacesystems.parser.RegressionSeverity
import com.whitespacesystems.parser.BenchmarkData
import com.whitespacesystems.parser.lexer.Lexer
import com.whitespacesystems.parser.parser.ZplParser
import io.kotest.core.spec.style.StringSpec
import io.kotest.matchers.collections.shouldNotBeEmpty
import io.kotest.matchers.should
import io.kotest.matchers.shouldBe
import io.kotest.matchers.shouldNotBe
import io.kotest.matchers.string.shouldContain
import io.kotest.matchers.types.shouldBeInstanceOf
import java.io.File

/**
 * Comprehensive test suite for the benchmarking infrastructure.
 * 
 * Tests benchmark execution, baseline comparison, regression detection,
 * and report generation to ensure the performance measurement system
 * works correctly and provides accurate results.
 */
class BenchmarkSystemTest : StringSpec({

    "should provide benchmark test data for all ZPL command types" {
        BenchmarkData.SIMPLE_COMMANDS shouldNotBeEmpty()
        BenchmarkData.SIMPLE_LABELS shouldNotBeEmpty()
        BenchmarkData.COMPLEX_LABELS shouldNotBeEmpty()
        BenchmarkData.LARGE_LABELS shouldNotBeEmpty()
        BenchmarkData.MEMORY_TEST_DATA shouldNotBeEmpty()
        
        // Verify ZPL command coverage
        val commands = BenchmarkData.SIMPLE_COMMANDS.joinToString()
        commands shouldContain "^XA" // Start Format
        commands shouldContain "^XZ" // End Format
        commands shouldContain "^FO" // Field Origin
        commands shouldContain "^FD" // Field Data
        commands shouldContain "^A"  // Font Command
    }

    "should generate consistent random test data" {
        val command1 = BenchmarkData.randomSimpleCommand()
        val command2 = BenchmarkData.randomSimpleCommand()
        
        // Should be valid ZPL commands
        command1 should { it.startsWith("^") }
        command2 should { it.startsWith("^") }
        
        val label1 = BenchmarkData.randomComplexLabel()
        val label2 = BenchmarkData.randomComplexLabel()
        
        // Should be complete labels
        label1 shouldContain "^XA"
        label1 shouldContain "^XZ"
        label2 shouldContain "^XA"
        label2 shouldContain "^XZ"
    }

    "should create valid benchmark results from ZPL parsing" {
        val simpleCommand = "^XA"
        val lexer = Lexer(simpleCommand)
        val startTime = System.nanoTime()
        val program = ZplParser(lexer.tokenize()).parse()
        val endTime = System.nanoTime()
        val executionTime = (endTime - startTime).toDouble()
        
        program shouldNotBe null
        program.commands.size shouldBe 1
        executionTime should { it > 0 }
        
        // Create benchmark result
        val result = BenchmarkResult(
            benchmarkName = "testBenchmarkStartFormat",
            commandName = "^XA",
            commandType = "simple",
            averageTimeNs = executionTime
        )
        
        result.benchmarkName shouldBe "testBenchmarkStartFormat"
        result.commandName shouldBe "^XA"
        result.commandType shouldBe "simple"
        result.averageTimeNs should { it > 0 }
    }

    "should create and manage performance baselines" {
        val testResults = mapOf(
            "benchmarkStartFormatCommand" to BenchmarkResult(
                benchmarkName = "benchmarkStartFormatCommand",
                commandName = "^XA",
                commandType = "simple",
                averageTimeNs = 50000.0 // 0.05ms - well under threshold
            ),
            "benchmarkFieldOriginCommand" to BenchmarkResult(
                benchmarkName = "benchmarkFieldOriginCommand", 
                commandName = "^FO",
                commandType = "complex",
                averageTimeNs = 800000.0 // 0.8ms - under threshold
            )
        )
        
        val baseline = BaselineComparison.createInitialBaseline(testResults)
        
        baseline.version shouldBe "1.0.0"
        baseline.commandBenchmarks shouldNotBeEmpty()
        baseline.commandBenchmarks.size shouldBe 2
        baseline.thresholds.simpleCommandsMaxNs shouldBe 100_000L
        baseline.thresholds.complexCommandsMaxNs shouldBe 1_000_000L
    }

    "should detect performance regression with baseline comparison" {
        // Create baseline with good performance
        val baselineResults = mapOf(
            "benchmarkStartFormatCommand" to BenchmarkResult(
                benchmarkName = "benchmarkStartFormatCommand",
                commandName = "^XA",
                averageTimeNs = 50000.0 // 0.05ms baseline
            )
        )
        val baseline = BaselineComparison.createInitialBaseline(baselineResults)
        
        // Create current results with regression (15% slower)
        val currentResults = mapOf(
            "benchmarkStartFormatCommand" to BenchmarkResult(
                benchmarkName = "benchmarkStartFormatCommand", 
                commandName = "^XA",
                averageTimeNs = 57500.0 // 0.0575ms - 15% regression
            )
        )
        
        val comparisons = BaselineComparison.compareWithBaseline(currentResults, baseline)
        
        comparisons.size shouldBe 1
        val comparison = comparisons[0]
        
        comparison.isRegression shouldBe true
        comparison.performanceDelta should { it > 10.0 } // >10% degradation
        comparison.regressionSeverity shouldBe RegressionSeverity.MODERATE
    }

    "should not detect regression when performance improves" {
        // Create baseline
        val baselineResults = mapOf(
            "benchmarkFieldDataCommand" to BenchmarkResult(
                benchmarkName = "benchmarkFieldDataCommand",
                commandName = "^FD", 
                averageTimeNs = 900000.0 // 0.9ms baseline
            )
        )
        val baseline = BaselineComparison.createInitialBaseline(baselineResults)
        
        // Create current results with improvement (20% faster)
        val currentResults = mapOf(
            "benchmarkFieldDataCommand" to BenchmarkResult(
                benchmarkName = "benchmarkFieldDataCommand",
                commandName = "^FD",
                averageTimeNs = 720000.0 // 0.72ms - 20% improvement
            )
        )
        
        val comparisons = BaselineComparison.compareWithBaseline(currentResults, baseline)
        
        comparisons.size shouldBe 1
        val comparison = comparisons[0]
        
        comparison.isRegression shouldBe false
        comparison.performanceDelta should { it < 0 } // Negative = improvement
        comparison.regressionSeverity shouldBe RegressionSeverity.NONE
    }

    "should generate comprehensive regression reports" {
        val baselineResults = mapOf(
            "benchmarkStartFormatCommand" to BenchmarkResult(
                benchmarkName = "benchmarkStartFormatCommand",
                commandName = "^XA",
                averageTimeNs = 50000.0
            ),
            "benchmarkFieldOriginCommand" to BenchmarkResult(
                benchmarkName = "benchmarkFieldOriginCommand",
                commandName = "^FO", 
                averageTimeNs = 800000.0
            )
        )
        val baseline = BaselineComparison.createInitialBaseline(baselineResults)
        
        // Create current results with mixed performance
        val currentResults = mapOf(
            "benchmarkStartFormatCommand" to BenchmarkResult(
                benchmarkName = "benchmarkStartFormatCommand",
                commandName = "^XA",
                averageTimeNs = 65000.0 // 30% regression - MODERATE
            ),
            "benchmarkFieldOriginCommand" to BenchmarkResult(
                benchmarkName = "benchmarkFieldOriginCommand", 
                commandName = "^FO",
                averageTimeNs = 700000.0 // 12.5% improvement
            )
        )
        
        val comparisons = BaselineComparison.compareWithBaseline(currentResults, baseline)
        val report = BaselineComparison.generateRegressionReport(comparisons)
        
        report shouldContain "Performance Regression Report"
        report shouldContain "benchmarkStartFormatCommand" // Regression entry
        report shouldContain "MODERATE" // Severity level
        report shouldContain "Performance Summary"
    }

    "should validate performance thresholds correctly" {
        val thresholds = PerformanceThresholds()
        
        val testResults = mapOf(
            "benchmarkStartFormatCommand" to BenchmarkResult(
                benchmarkName = "benchmarkStartFormatCommand",
                commandName = "^XA",
                averageTimeNs = 150000.0 // 0.15ms - exceeds 0.1ms threshold
            ),
            "benchmarkFieldOriginCommand" to BenchmarkResult(
                benchmarkName = "benchmarkFieldOriginCommand",
                commandName = "^FO",
                averageTimeNs = 800000.0 // 0.8ms - within 1ms threshold
            )
        )
        
        val failures = BaselineComparison.checkPerformanceThresholds(testResults, thresholds)
        
        failures.size shouldBe 1
        failures[0] shouldContain "benchmarkStartFormatCommand"
        failures[0] shouldContain "exceeds threshold"
    }

    "should handle baseline persistence correctly" {
        val testResults = mapOf(
            "benchmarkTest" to BenchmarkResult(
                benchmarkName = "benchmarkTest",
                averageTimeNs = 100000.0
            )
        )
        
        val originalBaseline = BaselineComparison.createInitialBaseline(testResults)
        
        // Save and load baseline
        BaselineComparison.saveBaseline(originalBaseline)
        val loadedBaseline = BaselineComparison.loadBaseline()
        
        loadedBaseline shouldNotBe null
        loadedBaseline?.version shouldBe originalBaseline.version
        loadedBaseline?.commandBenchmarks?.size shouldBe originalBaseline.commandBenchmarks.size
        
        // Clean up test file
        File("benchmarks/baselines/baseline.json").delete()
    }

    "should update baseline with historical tracking" {
        val initialResults = mapOf(
            "benchmarkTest" to BenchmarkResult(
                benchmarkName = "benchmarkTest",
                averageTimeNs = 100000.0,
                timestamp = 1000L
            )
        )
        val baseline = BaselineComparison.createInitialBaseline(initialResults)
        
        val newResults = mapOf(
            "benchmarkTest" to BenchmarkResult(
                benchmarkName = "benchmarkTest",
                averageTimeNs = 110000.0,
                timestamp = 2000L
            )
        )
        
        val updatedBaseline = BaselineComparison.updateBaseline(newResults, baseline, "1.1.0")
        
        updatedBaseline.history.measurements.size shouldBe 1
        updatedBaseline.history.measurements[0].version shouldBe "1.1.0"
        updatedBaseline.history.measurements[0].results shouldBe newResults
    }

    "should handle benchmark infrastructure edge cases" {
        // Test with empty results
        val emptyComparisons = BaselineComparison.compareWithBaseline(
            emptyMap(),
            BaselineComparison.createInitialBaseline(emptyMap())
        )
        emptyComparisons shouldBe emptyList()
        
        // Test report generation with no regressions
        val noRegressionReport = BaselineComparison.generateRegressionReport(emptyList())
        noRegressionReport shouldContain "No performance regressions detected"
        
        // Test threshold validation with empty results
        val noFailures = BaselineComparison.checkPerformanceThresholds(
            emptyMap(),
            PerformanceThresholds()
        )
        noFailures shouldBe emptyList()
    }

    "should measure realistic parsing performance for benchmark validation" {
        // Test that actual parsing meets expected performance characteristics
        val commands = listOf("^XA", "^XZ", "^FO100,50", "^FDTest", "^A0N,30,30")
        
        commands.forEach { command ->
            val iterations = 1000
            val times = mutableListOf<Long>()
            
            repeat(iterations) {
                val lexer = Lexer(command)
                val startTime = System.nanoTime()
                val program = ZplParser(lexer.tokenize()).parse()
                val endTime = System.nanoTime()
                
                program shouldNotBe null
                times.add(endTime - startTime)
            }
            
            val averageTime = times.average()
            val commandType = if (command == "^XA" || command == "^XZ") "simple" else "complex"
            val threshold = if (commandType == "simple") 100_000.0 else 1_000_000.0
            
            println("Command $command: ${String.format("%.0f", averageTime)}ns avg (threshold: ${threshold.toLong()}ns)")
            
            // Note: In CI/CD, this might occasionally exceed thresholds due to environment variance
            // In production, this would be a warning rather than a hard failure
        }
    }
})